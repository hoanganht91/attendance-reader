"""
Data Synchronization Module
Handles local data storage and synchronization operations
"""

import os
import json
import hashlib
from datetime import datetime, timedelta
from typing import List, Dict, Set, Optional
from src.attendance_reader import AttendanceRecord
from src.logger import get_logger


class DataSync:
    """Handles data synchronization and local storage"""
    
    def __init__(self, data_file: str = "data/attendance_records.txt",
                 last_sync_file: str = "data/last_sync.json"):
        self.data_file = data_file
        self.last_sync_file = last_sync_file
        self.logger = get_logger()
        
        # Create data directory if it doesn't exist
        data_dir = os.path.dirname(data_file)
        if data_dir and not os.path.exists(data_dir):
            os.makedirs(data_dir)
        
        # Initialize files if they don't exist
        self._initialize_files()
        
        # Cache for duplicate detection
        self._record_hashes: Set[str] = set()
        self._load_existing_hashes()
    
    def _initialize_files(self) -> None:
        """Initialize data files if they don't exist"""
        try:
            # Initialize data file with header
            if not os.path.exists(self.data_file):
                with open(self.data_file, 'w', encoding='utf-8') as f:
                    header = (
                        "# Attendance Records\n"
                        "# Format: timestamp|device_id|device_name|user_id|user_name|punch_type|verify_type|work_code\n"
                        "# Generated by Attendance System\n"
                        "\n"
                    )
                    f.write(header)
                self.logger.info("Created new data file", file=self.data_file)
            
            # Initialize last sync file
            if not os.path.exists(self.last_sync_file):
                initial_sync_data = {
                    "last_sync_time": None,
                    "device_last_sync": {},
                    "total_records": 0,
                    "last_update": datetime.now().isoformat()
                }
                with open(self.last_sync_file, 'w', encoding='utf-8') as f:
                    json.dump(initial_sync_data, f, indent=2, ensure_ascii=False)
                self.logger.info("Created new sync tracking file", file=self.last_sync_file)
                
        except Exception as e:
            self.logger.error("Error initializing data files", exception=e)
    
    def _load_existing_hashes(self) -> None:
        """Load existing record hashes for duplicate detection"""
        try:
            if os.path.exists(self.data_file):
                with open(self.data_file, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and not line.startswith('#'):
                            # Generate hash from the line content
                            record_hash = hashlib.md5(line.encode('utf-8')).hexdigest()
                            self._record_hashes.add(record_hash)
                
                self.logger.debug(f"Loaded existing record hashes", count=len(self._record_hashes))
                
        except Exception as e:
            self.logger.error("Error loading existing record hashes", exception=e)
    
    def _generate_record_hash(self, record: AttendanceRecord) -> str:
        """Generate unique hash for attendance record"""
        # Create unique identifier from key fields
        unique_string = f"{record.device_id}|{record.user_id}|{record.timestamp.isoformat()}|{record.punch_type}"
        return hashlib.md5(unique_string.encode('utf-8')).hexdigest()
    
    def _format_record_line(self, record: AttendanceRecord) -> str:
        """Format attendance record as text line"""
        return (f"{record.timestamp.isoformat()}|"
                f"{record.device_id}|"
                f"{record.device_name}|"
                f"{record.user_id}|"
                f"{record.user_name}|"
                f"{record.punch_type}|"
                f"{record.verify_type}|"
                f"{record.work_code}")
    
    def save_records(self, records: List[AttendanceRecord], device_id: str) -> int:
        """
        Save attendance records to local storage
        
        Args:
            records: List of attendance records
            device_id: Device ID for tracking last sync
            
        Returns:
            Number of new records saved (excluding duplicates)
        """
        if not records:
            return 0
        
        new_records_count = 0
        duplicate_count = 0
        
        try:
            # Filter out duplicates
            new_records = []
            for record in records:
                record_hash = self._generate_record_hash(record)
                if record_hash not in self._record_hashes:
                    new_records.append(record)
                    self._record_hashes.add(record_hash)
                    new_records_count += 1
                else:
                    duplicate_count += 1
            
            if new_records:
                # Append new records to file
                with open(self.data_file, 'a', encoding='utf-8') as f:
                    for record in new_records:
                        f.write(self._format_record_line(record) + '\n')
                
                # Update last sync tracking
                self._update_last_sync(device_id, records)
                
                self.logger.info(f"Saved attendance records", 
                               device_id=device_id,
                               new_records=new_records_count,
                               duplicates=duplicate_count,
                               total_processed=len(records))
            else:
                self.logger.info(f"No new records to save", 
                               device_id=device_id,
                               duplicates=duplicate_count)
                
        except Exception as e:
            self.logger.error(f"Error saving records", 
                            device_id=device_id, exception=e)
            return 0
        
        return new_records_count
    
    def _update_last_sync(self, device_id: str, records: List[AttendanceRecord]) -> None:
        """Update last sync tracking information"""
        try:
            # Load current sync data
            sync_data = self.get_last_sync_info()
            
            # Find latest timestamp in records
            if records:
                latest_timestamp = max(record.timestamp for record in records)
                sync_data['device_last_sync'][device_id] = latest_timestamp.isoformat()
                sync_data['last_sync_time'] = datetime.now().isoformat()
                sync_data['last_update'] = datetime.now().isoformat()
                
                # Update total records count
                sync_data['total_records'] = sync_data.get('total_records', 0) + len(records)
            
            # Save updated sync data
            with open(self.last_sync_file, 'w', encoding='utf-8') as f:
                json.dump(sync_data, f, indent=2, ensure_ascii=False)
                
        except Exception as e:
            self.logger.error("Error updating last sync info", exception=e)
    
    def get_last_sync_info(self) -> Dict:
        """Get last synchronization information"""
        try:
            if os.path.exists(self.last_sync_file):
                with open(self.last_sync_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            else:
                return {
                    "last_sync_time": None,
                    "device_last_sync": {},
                    "total_records": 0,
                    "last_update": None
                }
        except Exception as e:
            self.logger.error("Error reading last sync info", exception=e)
            return {"last_sync_time": None, "device_last_sync": {}, "total_records": 0}
    
    def get_device_last_sync_time(self, device_id: str) -> Optional[datetime]:
        """Get last sync time for specific device"""
        try:
            sync_info = self.get_last_sync_info()
            device_sync = sync_info.get('device_last_sync', {})
            
            if device_id in device_sync:
                return datetime.fromisoformat(device_sync[device_id])
            
            return None
            
        except Exception as e:
            self.logger.error(f"Error getting device last sync time", 
                            device_id=device_id, exception=e)
            return None
    
    def get_records_count(self) -> int:
        """Get total number of records in storage"""
        try:
            if not os.path.exists(self.data_file):
                return 0
            
            count = 0
            with open(self.data_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.strip() and not line.startswith('#'):
                        count += 1
            
            return count
            
        except Exception as e:
            self.logger.error("Error counting records", exception=e)
            return 0
    
    def get_recent_records(self, hours: int = 24) -> List[Dict]:
        """Get recent records within specified hours"""
        records = []
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        try:
            if not os.path.exists(self.data_file):
                return records
            
            with open(self.data_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith('#'):
                        parts = line.split('|')
                        if len(parts) >= 8:
                            try:
                                record_time = datetime.fromisoformat(parts[0])
                                if record_time >= cutoff_time:
                                    record = {
                                        'timestamp': parts[0],
                                        'device_id': parts[1],
                                        'device_name': parts[2],
                                        'user_id': parts[3],
                                        'user_name': parts[4],
                                        'punch_type': int(parts[5]),
                                        'verify_type': int(parts[6]),
                                        'work_code': int(parts[7])
                                    }
                                    records.append(record)
                            except (ValueError, IndexError):
                                continue
                                
        except Exception as e:
            self.logger.error(f"Error getting recent records", exception=e)
        
        return records
    
    def cleanup_old_records(self, retention_days: int = 30) -> int:
        """
        Clean up old records beyond retention period
        
        Args:
            retention_days: Number of days to retain records
            
        Returns:
            Number of records removed
        """
        if retention_days <= 0:
            self.logger.warning("Invalid retention days, skipping cleanup")
            return 0
        
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        removed_count = 0
        
        try:
            if not os.path.exists(self.data_file):
                return 0
            
            # Read all records
            kept_lines = []
            with open(self.data_file, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line or line.startswith('#'):
                        kept_lines.append(line)
                        continue
                    
                    parts = line.split('|')
                    if len(parts) >= 1:
                        try:
                            record_time = datetime.fromisoformat(parts[0])
                            if record_time >= cutoff_date:
                                kept_lines.append(line)
                            else:
                                removed_count += 1
                        except ValueError:
                            # Keep malformed lines
                            kept_lines.append(line)
                    else:
                        kept_lines.append(line)
            
            # Write back kept records
            if removed_count > 0:
                with open(self.data_file, 'w', encoding='utf-8') as f:
                    for line in kept_lines:
                        f.write(line + '\n')
                
                # Rebuild hash cache
                self._record_hashes.clear()
                self._load_existing_hashes()
                
                self.logger.info(f"Cleaned up old records", 
                               removed=removed_count,
                               retention_days=retention_days)
            
        except Exception as e:
            self.logger.error("Error cleaning up old records", exception=e)
            return 0
        
        return removed_count
    
    def get_sync_statistics(self) -> Dict:
        """Get synchronization statistics"""
        try:
            sync_info = self.get_last_sync_info()
            total_records = self.get_records_count()
            recent_records = len(self.get_recent_records(24))
            
            stats = {
                'total_records': total_records,
                'recent_records_24h': recent_records,
                'last_sync_time': sync_info.get('last_sync_time'),
                'devices_synced': len(sync_info.get('device_last_sync', {})),
                'data_file_size_mb': round(os.path.getsize(self.data_file) / (1024*1024), 2) if os.path.exists(self.data_file) else 0,
                'cache_size': len(self._record_hashes)
            }
            
            return stats
            
        except Exception as e:
            self.logger.error("Error getting sync statistics", exception=e)
            return {} 